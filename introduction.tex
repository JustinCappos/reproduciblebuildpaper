\section{Introduction}
\label{SEC:introduction}

Since Ken Thompson's Turing award lecture about `Trusting Trust' 
\cappos{cite}, the security world has been concerned about the potential
for backdoors in build infrastructure.  Concerns about malicious compilers
and build systems are not
theoretical, with dozens of companies compromised due to attacks in the
build infrastructure \cappos{tons of cites}.  For example, in 2008?
Fedora's build system was compromised by a malicious actor \cappos{cite}.
Despite adding a hardware security module in response to this intrusion, 
an attacker managed to subsequently compromise the build server in 2009? 
and sign maliciously backdoored copies of the OpenSSH package
\cappos{cite}.

As a response to these security concerns, there have been recent
efforts to make \emph{reproducible builds} \cappos{cite}.  A reproducible
build is one where two different parties with similar setups\footnote{we 
will more precisely define this in Section X.\cappos{fix}} are able 
to obtain bitwise identical binaries from the same source code
\cappos{perhaps find an official definition instead}.  
The idea is that if different parties are able to build the same binary
from source, then either none of their build systems are compromised or
they are all compromised in the same way.

Surprisingly, very few pieces of software are built reproducibly without
effort on behalf of the software maintainer or changes to the build system
itself.  For example, only XX\% of packages from Debian in 2014? would even
produce identical binaries if the build process was run twice on the same
build system.  The reasons for this, which are described in more detail
in Section X\cappos{fix}, in the majority of cases deal with the use
of timestamps (5X\%), timezone information (3X\%), locale information
(2X\%), or date (4X\%) \cappos{please check / fix}.  There are hundreds of
more subtle issues in software that are resolved on a case-by-case basis
\cappos{cite}.

In this paper, we describe experiences from a major Linux distribution's
efforts to make software build in a reproducible manner.  Interestingly,
the major benefit discovered so far from reproducible builds has not been 
security.  The effort of making builds reproducible has uncovered a large
number of latent bugs in software packages.  Our experiences demonstrate
that reproducible builds are perhaps even more effective as a technique
for software quality assurance.

Reasoning about reproducible builds as a quality assurance tool, has led to
a different set of design choices and decisions than other reproducible
builds efforts.  Many efforts to make reproducible builds attempt to make
an environment that solves common reproducibility issues (such as
timestamps, locales, etc.) by running in an emulated environment or
container.   Others do a post-processing step to try to strip this
information out of binaries, images, compressed archives, etc.  Using the
lens of quality assurance, we instead focus on addressing the root cause of
the errors in the relevant tools (i.e., fixing issues upstream).  This
technique of fixing the root cause, as opposed to `papering over' issues,
has led us to find a number of latent bugs that were undiscovered for many
years.\cappos{fix} 

The main contributions in this work are as follows:

\begin{itemize}
\item We report on the experience from a major Linux distribution's
multi-year effort with reproducibly building 3XK packages.  We provide
details about the tools, techniques, and strategies that have proven
effective at making builds reproducible.  Through these efforts, 9X\% of 
the packages now build reproducibly.

\item The value of reproducible builds is clearly elucidated.  While the
value for security is well recognized, fixing issues with reproducible
builds has also led to the discovery of XXX bugs, including XX major
security vulnerabilities.  This demonstrates an auxiliary benefit that goes
far beyond the way in which reproducible builds are currently used.

\item This paper clearly describes the choices between fixing bugs that
lead to a lack of reproducibility in different places in the toolchain
(fixing upstream or `papering over' differences at the end).
While, different choices have been made by different projects that perform 
reproducible builds, we demonstrate that this enabled us to find an array
of bugs that were missed by other efforts.

%\item Using our experiences, we speculate about ways in which varying the
%build environment may assist in finding new bugs across applications. 
%To test our ideas, we prototyped \sysname, a system for emulating diverse build 
%environments. \cappos{optional.  I can tweak if we don't get something
%like this together.}  While \sysname finds some issues, the current
%prototype is more useful for illustrating the research challenges than 
%for solving the community's need.  We hope that our work in this area 
%motivate researchers to devise efficient ways to check diverse operating 
%environments or inspire techniques for ensuring the fidelity of the emulated 
%environments. 
\end{itemize}


The remainder of this paper is organized as follows.  First, Section XX
describes the concepts behind reproducibility, including the philisophical
arguments about which differences should be allowed in build environments.
Following this, common tools and techniques for addressing reproducibility
are discussed in Section Y.  Subsequently, Section Z discusses our 
experiences with making builds reproducible is described, including both 
anecdotal experiences and a quantification of which techniques worked on 
what set of packages.  Using this context, Section XXX then does a deep
dive into the more general bugs found when looking for reproducible
build issues.  This shows situations where our philosophy of fixing bugs in
the original source paid dividends in fixing important software flaws
elsewhere.  
%Given more information about these bugs, Section Y describes
%\sysname, a prototype that helps to automate exploration if one of these
%types of bugs exists in an application's build.  
Section XX discusses
related work, primarily on software testing and build, before the paper
concludes.

